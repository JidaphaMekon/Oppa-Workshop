# -*- coding: utf-8 -*-
"""Untitled42.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eJEyTZP00jIJSFoxHw9ZS4dcqr2xmk73
"""

# -*- coding: utf-8 -*-
"""Model-3-Linear_interp_lag7_5-models-ActualOnly.ipynb
---
‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå: ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Metrics) ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏¥‡∏î‡∏à‡∏£‡∏¥‡∏á (Actual Close) ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
"""

# ----------------------------------------------------
# 0. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ
# ----------------------------------------------------
!pip install pandas_market_calendars
!pip install yfinance scikit-learn xgboost matplotlib tqdm

import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import pandas_market_calendars as mcal
from tqdm import tqdm

# ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Machine Learning
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from xgboost import XGBRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler

# ------------------------------
# 0. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î list ‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
# ------------------------------
tickers = ["AAPL", "AMD", "AVGO", "GOOG", "GOOGL", "META", "MSFT", "NVDA"]
start_date = datetime(2019, 1, 1)
end_date   = datetime(2024, 12, 31)
all_data_list = []

# ------------------------------
# 1. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
# ------------------------------
for ticker in tickers:
    print(f"üì• Downloading {ticker} ...")
    data = yf.download(ticker, start=start_date.strftime('%Y-%m-%d'), end=end_date.strftime('%Y-%m-%d'))

    if data.empty:
        print(f"‚ùå No data for {ticker}")
        continue

    data.reset_index(inplace=True)

    # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
    if isinstance(data.columns, pd.MultiIndex):
        data.columns = [' '.join(col).strip() if isinstance(col, tuple) else col for col in data.columns.values]

    def clean_columns(cols):
        cleaned = []
        for col in cols:
            if 'Date' in col: cleaned.append('Date')
            else: cleaned.append(col.split()[0])
        return cleaned

    data.columns = clean_columns(data.columns)
    data['Symbol'] = ticker.upper()

    wanted_cols = ['Date', 'Open','High','Low','Close', 'Volume', 'Symbol']
    data = data[[col for col in wanted_cols if col in data.columns]]
    all_data_list.append(data)

flat_df = pd.concat(all_data_list, ignore_index=True)
print("‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

# ----------------------------------------------------
# 2. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î + Nearest Neighbor Interpolation ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á Flag
# ----------------------------------------------------
# 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á continuous date range
all_dates = pd.DataFrame({'Date': pd.date_range(flat_df['Date'].min(), flat_df['Date'].max())})
symbols = flat_df['Symbol'].unique()
expanded_list = []
for sym in symbols:
    temp = all_dates.copy()
    temp['Symbol'] = sym
    expanded_list.append(temp)
all_dates_symbols = pd.concat(expanded_list, ignore_index=True)

# 2. merge ‡∏Å‡∏±‡∏ö flat_df (‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ 'Close' ‡∏°‡∏µ NaN ‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î)
full_df = all_dates_symbols.merge(flat_df, on=['Date','Symbol'], how='left')

# **‚≠êÔ∏è ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°: ‡∏™‡∏£‡πâ‡∏≤‡∏á Flag ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏¥‡∏î‡∏à‡∏£‡∏¥‡∏á (Actual Close) ‚≠êÔ∏è**
# Flag 1 ‡∏ñ‡πâ‡∏≤ Close ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ (‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô NaN) -> ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏¥‡∏î‡∏à‡∏£‡∏¥‡∏á
# Flag 0 ‡∏ñ‡πâ‡∏≤ Close ‡πÄ‡∏õ‡πá‡∏ô NaN -> ‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î (‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ)
full_df['Is_Actual_Close'] = full_df['Close'].notna().astype(float)


# 3. ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á Close ‡∏î‡πâ‡∏ß‡∏¢ nearest (Interpolation)
price_cols = ['Close']
for col in price_cols:
    full_df[col] = full_df.groupby('Symbol')[col].transform(
        lambda x: x.interpolate(method='nearest')
    )
# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ OHLCV ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô 0 ‡∏´‡∏£‡∏∑‡∏≠ NaN
full_df[['Open','High','Low','Volume']] = full_df[['Open','High','Low','Volume']].fillna(0)

print("\n‚úÖ ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î‡πÅ‡∏•‡∏∞ Nearest Neighbor Interpolation ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")

# ----------------------------------------------------
# 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Lag-7 Features ‡πÅ‡∏•‡∏∞ Target
# ----------------------------------------------------
lag_cols = []
for lag in range(1, 8):
    col_name = f'Close_lag{lag}'
    full_df[col_name] = full_df.groupby('Symbol')['Close'].shift(lag)
    lag_cols.append(col_name)

# 9. ‡∏™‡∏£‡πâ‡∏≤‡∏á Target: Close ‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ (‡πÉ‡∏ä‡πâ Close ‡∏ó‡∏µ‡πà Interpolate ‡πÅ‡∏•‡πâ‡∏ß)
full_df['Close_next'] = full_df.groupby('Symbol')['Close'].shift(-1)

# **‚≠êÔ∏è ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°: Shift Flag ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö Target ‚≠êÔ∏è**
# Is_Actual_Target = 1.0 ‡∏ñ‡πâ‡∏≤ Close_next ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏Ñ‡∏≤‡∏à‡∏£‡∏¥‡∏á (‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô)
full_df['Is_Actual_Target'] = full_df.groupby('Symbol')['Is_Actual_Close'].shift(-1)

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Feature Matrix X
X_cols = lag_cols
print("\n‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Lag-7 Features ‡πÅ‡∏•‡∏∞ Target (Close_next) ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")

# ----------------------------------------------------
# 4. Sliding Window (70/15/15) ‡πÅ‡∏•‡∏∞ Model Training/Evaluation
# ----------------------------------------------------
window_train = 0.7
window_test = 0.15

# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏• (5 ‡πÇ‡∏°‡πÄ‡∏î‡∏•)
models = {
    'Linear': LinearRegression(),
    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),
    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42),
    'XGBoost': XGBRegressor(n_estimators=100, random_state=42, verbosity=0, n_jobs=-1),
    'SVR': SVR()
}

# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
all_results = []
window_predictions_full = []
model_name = "Linearinterp_lag7_ActualOnly"

# Loop ‡πÅ‡∏ï‡πà‡∏•‡∏∞ Symbol
for sym in tqdm(symbols, desc="Training models with Sliding Window (Actual Only)"):
    df_sym = full_df[full_df['Symbol'] == sym].sort_values('Date').reset_index(drop=True)

    # Feature, Target ‡πÅ‡∏•‡∏∞ Flag
    data_ml = df_sym[['Date'] + X_cols + ['Close_next', 'Is_Actual_Target']].dropna().reset_index(drop=True)

    X_clean = data_ml[X_cols]
    y_clean = data_ml['Close_next']
    is_actual_target_clean = data_ml['Is_Actual_Target']
    date_clean = data_ml['Date']

    n = len(X_clean)
    step = int(n * window_test)
    start = 0
    window_id = 1

    # Sliding Window Loop
    while start + int(n * window_train) + step <= n:
        train_idx = range(start, start + int(n*window_train))
        test_idx  = range(start + int(n*window_train), start + int(n*window_train) + step)

        X_train = X_clean.iloc[train_idx].values
        y_train = y_clean.iloc[train_idx].values
        X_test  = X_clean.iloc[test_idx].values
        y_test  = y_clean.iloc[test_idx].values

        # ‡∏î‡∏∂‡∏á Flag ‡∏Ç‡∏≠‡∏á Test Set
        is_actual_test = is_actual_target_clean.iloc[test_idx].values
        date_test = date_clean.iloc[test_idx].values

        # Scale Training set
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled  = scaler.transform(X_test)

        # Train & Evaluate ‡∏ó‡∏∏‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
        for name, model in models.items():
            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_test_scaled)

            # **‚≠êÔ∏è ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á: ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Target ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏Ñ‡∏≤‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (Is_Actual_Target = 1.0) ‚≠êÔ∏è**

            actual_mask = (is_actual_test == 1.0)
            y_test_actual = y_test[actual_mask]
            y_pred_actual = y_pred[actual_mask]

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if len(y_test_actual) > 0:
                 # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Metrics ‡∏ö‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
                 all_results.append({
                    'Symbol': sym,
                    'model': name,
                    'Window': window_id,
                    'start_idx': start,
                    'rmse': np.sqrt(mean_squared_error(y_test_actual, y_pred_actual)),
                    'mae': mean_absolute_error(y_test_actual, y_pred_actual),
                    'r2': r2_score(y_test_actual, y_pred_actual),
                    'Model Name': model_name
                 })

            # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (Predicted vs. Actual)
            temp_df = pd.DataFrame({
                'Date': date_test,
                'Symbol': sym,
                'Window': window_id,
                'model': name,
                'Actual_Close_next': y_test,
                'Predicted_Close_next': y_pred,
                'Is_Actual_Target': is_actual_test
            })
            window_predictions_full.append(temp_df)

        start += step
        window_id += 1

# ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô DataFrame
results_df = pd.DataFrame(all_results)
window_predictions_df = pd.concat(window_predictions_full, axis=0).reset_index(drop=True)

print("\n‚úÖ ‡∏ù‡∏∂‡∏Å‡∏ù‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

# ----------------------------------------------------
# 5. ‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞ Export ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
# ----------------------------------------------------

# Export results_df (‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å Window)
results_df.to_excel("results_ActualOnly_lag7.xlsx", index=False)
print("‚úÖ Exported results (Actual Only) to results_ActualOnly_lag7.xlsx")

# ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Average Metrics)
average_results = results_df.groupby('model')[['rmse', 'mae', 'r2']].mean().reset_index()

# ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
format_mapping = {
    'rmse': '{:,.4f}'.format,
    'mae': '{:,.4f}'.format,
    'r2': '{:,.4f}'.format
}
average_results_formatted = average_results.copy()
for col, formatter in format_mapping.items():
    average_results_formatted[col] = average_results_formatted[col].apply(formatter)

print("\n--- üìà ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (Actual Dates Only) ---")
print(average_results_formatted)

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏•‡∏á‡πÉ‡∏ô Excel
average_results.to_excel("average_results_ActualOnly_lag7.xlsx", index=False)
print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏•‡∏á‡πÉ‡∏ô average_results_ActualOnly_lag7.xlsx")

# Export ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (Predicted vs. Actual) - ‡∏£‡∏ß‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡πÑ‡∏ß‡πâ ‡πÅ‡∏ï‡πà‡∏°‡∏µ Flag ‡∏Å‡∏≥‡∏Å‡∏±‡∏ö
window_predictions_df.to_excel("predictions_full_details_ActualOnly_lag7.xlsx", index=False)
print("‚úÖ Exported ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (Predicted vs. Actual) to predictions_full_details_ActualOnly_lag7.xlsx")

print("\n--- ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå ---")

import pandas as pd
import matplotlib.pyplot as plt

# 1. ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
file_path = "predictions_full_details_ActualOnly_lag7.xlsx"
try:
    predictions_df = pd.read_excel(file_path)
except FileNotFoundError:
    print(f"‚ùå Error: File not found at {file_path}. Please run the full code first.")
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡πÄ‡∏õ‡∏•‡πà‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
    predictions_df = pd.DataFrame()

if not predictions_df.empty:
    # 2. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Symbol ‡πÅ‡∏•‡∏∞ Window ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á
    TARGET_SYMBOL = 'AAPL' # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏ô‡πÉ‡∏à

    # ‡∏´‡∏≤‡∏ß‡∏¥‡∏ô‡πÇ‡∏î‡∏ß‡πå ID ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á Symbol ‡∏ô‡∏±‡πâ‡∏ô‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    max_window = predictions_df[predictions_df['Symbol'] == TARGET_SYMBOL]['Window'].max()

    # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Symbol ‡πÅ‡∏•‡∏∞ Window ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
    plot_data = predictions_df[
        (predictions_df['Symbol'] == TARGET_SYMBOL) &
        (predictions_df['Window'] == max_window)
    ]

    if plot_data.empty:
        print(f"‚ùå No data found for {TARGET_SYMBOL} in Window {max_window}.")
    else:
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ Plotting
        # ‡πÉ‡∏ä‡πâ Date ‡πÄ‡∏õ‡πá‡∏ô Index
        plot_data = plot_data.set_index('Date').sort_index()

        # ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤‡∏à‡∏£‡∏¥‡∏á (Actual) - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÇ‡∏î‡∏¢ reset_index ‡∏Å‡πà‡∏≠‡∏ô drop_duplicates ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ 'Date' ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
        actual_price = plot_data.reset_index().drop_duplicates(subset=['Date']).set_index('Date')['Actual_Close_next']

        # 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü
        plt.figure(figsize=(14, 7))

        # Plot ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏à‡∏£‡∏¥‡∏á (Actual)
        plt.plot(actual_price, label='Actual Close Price (Next Day)', color='black', linewidth=3)

        # Plot ‡∏Ñ‡πà‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•
        models_to_plot = plot_data['model'].unique()

        for model_name in models_to_plot:
            model_predictions = plot_data[plot_data['model'] == model_name]['Predicted_Close_next']
            plt.plot(model_predictions, label=f'Predicted: {model_name}', linestyle='--')

        # 4. ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü
        plt.title(f'Forecast vs. Actual Price for {TARGET_SYMBOL} (Window ID: {max_window})', fontsize=16)
        plt.xlabel('Date', fontsize=12)
        plt.ylabel('Price (USD)', fontsize=12)
        plt.legend(loc='upper left')
        plt.grid(True, alpha=0.5)
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# 1. ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
file_path_avg = "average_results_ActualOnly_lag7.xlsx"
try:
    average_results = pd.read_excel(file_path_avg)
except FileNotFoundError:
    print(f"‚ùå Error: File not found at {file_path_avg}. Please ensure the full code was run successfully.")
    average_results = pd.DataFrame()

if not average_results.empty:
    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô Index ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£ Plot
    average_results = average_results.set_index('model')

    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•
    model_colors = {
        'Linear': '#1f77b4',       # Blue
        'RandomForest': '#ff7f0e', # Orange
        'GradientBoosting': '#2ca02c', # Green
        'XGBoost': '#d62728',      # Red
        'SVR': '#9467bd'           # Purple
    }

    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏≤‡∏°‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏µ‡∏Ñ‡∏á‡∏ó‡∏µ‡πà
    models = average_results.index.tolist()
    colors = [model_colors.get(m, 'gray') for m in models]

    # --- ‡∏Å‡∏£‡∏≤‡∏ü‡∏ó‡∏µ‡πà 1: ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö RMSE ---
    plt.figure(figsize=(12, 6))

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏ó‡πà‡∏á
    bars = plt.bar(models, average_results['rmse'], color=colors)

    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ö‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü
    for bar in bars:
        yval = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.01, f'{yval:.4f}', ha='center', va='bottom', fontsize=10)

    plt.title('Average RMSE Comparison Across 5 Models (Actual Dates Only)', fontsize=16)
    plt.xlabel('Forecasting Model', fontsize=12)
    plt.ylabel('Average RMSE', fontsize=12)
    plt.grid(axis='y', alpha=0.5)
    plt.show()

    # --- ‡∏Å‡∏£‡∏≤‡∏ü‡∏ó‡∏µ‡πà 2: ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö R¬≤ ---
    plt.figure(figsize=(12, 6))

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏ó‡πà‡∏á
    bars = plt.bar(models, average_results['r2'], color=colors)

    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ö‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü
    for bar in bars:
        yval = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.0005, f'{yval:.4f}', ha='center', va='bottom', fontsize=10)

    plt.title('Average R-squared (R¬≤) Comparison Across 5 Models (Actual Dates Only)', fontsize=16)
    plt.xlabel('Forecasting Model', fontsize=12)
    plt.ylabel('Average R¬≤', fontsize=12)
    plt.ylim(average_results['r2'].min() - 0.005, 1.0) # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÅ‡∏Å‡∏ô y ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô
    plt.grid(axis='y', alpha=0.5)
    plt.show()

# -*- coding: utf-8 -*-
"""Model-5-Lag7_TechIndicators_ActualOnly.ipynb
---
‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå: ‡∏£‡∏ß‡∏° Lag-7 ‡πÅ‡∏•‡∏∞ Technical Indicators (SMA, RSI, MACD) ‡πÄ‡∏õ‡πá‡∏ô Features
‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ß‡∏±‡∏ô‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏¥‡∏á (Actual Dates Only)
"""

# ----------------------------------------------------
# 0. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ
# ----------------------------------------------------
!pip install pandas_market_calendars
!pip install yfinance scikit-learn xgboost matplotlib tqdm

import yfinance as yf
import pandas as pd
import numpy as np
from datetime import datetime
import pandas_market_calendars as mcal
from tqdm import tqdm

# ‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Machine Learning
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from xgboost import XGBRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler

# ------------------------------
# 0. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î list ‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
# ------------------------------
tickers = ["AAPL", "AMD", "AVGO", "GOOG", "GOOGL", "META", "MSFT", "NVDA"]
start_date = datetime(2019, 1, 1)
end_date   = datetime(2024, 12, 31)
all_data_list = []

# ------------------------------
# 1. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏∏‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
# ------------------------------
for ticker in tickers:
    print(f"üì• Downloading {ticker} ...")
    data = yf.download(ticker, start=start_date.strftime('%Y-%m-%d'), end=end_date.strftime('%Y-%m-%d'))

    if data.empty:
        print(f"‚ùå No data for {ticker}")
        continue

    data.reset_index(inplace=True)

    if isinstance(data.columns, pd.MultiIndex):
        data.columns = [' '.join(col).strip() if isinstance(col, tuple) else col for col in data.columns.values]

    def clean_columns(cols):
        cleaned = []
        for col in cols:
            if 'Date' in col: cleaned.append('Date')
            else: cleaned.append(col.split()[0])
        return cleaned

    data.columns = clean_columns(data.columns)
    data['Symbol'] = ticker.upper()

    wanted_cols = ['Date', 'Open','High','Low','Close', 'Volume', 'Symbol']
    data = data[[col for col in wanted_cols if col in data.columns]]
    all_data_list.append(data)

flat_df = pd.concat(all_data_list, ignore_index=True)
print("‚úÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

# ----------------------------------------------------
# 2. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î + Nearest Neighbor Interpolation ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á Flag
# ----------------------------------------------------
# 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á continuous date range
all_dates = pd.DataFrame({'Date': pd.date_range(flat_df['Date'].min(), flat_df['Date'].max())})
symbols = flat_df['Symbol'].unique()
expanded_list = []
for sym in symbols:
    temp = all_dates.copy()
    temp['Symbol'] = sym
    expanded_list.append(temp)
all_dates_symbols = pd.concat(expanded_list, ignore_index=True)

# 2. merge ‡∏Å‡∏±‡∏ö flat_df (‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ 'Close' ‡∏°‡∏µ NaN ‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î)
full_df = all_dates_symbols.merge(flat_df, on=['Date','Symbol'], how='left')

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Flag ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏¥‡∏î‡∏à‡∏£‡∏¥‡∏á (Actual Close)
full_df['Is_Actual_Close'] = full_df['Close'].notna().astype(float)

# 3. ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á Close ‡∏î‡πâ‡∏ß‡∏¢ nearest (Interpolation)
price_cols = ['Close']
for col in price_cols:
    full_df[col] = full_df.groupby('Symbol')[col].transform(
        lambda x: x.interpolate(method='nearest')
    )
full_df[['Open','High','Low','Volume']] = full_df[['Open','High','Low','Volume']].fillna(0)

print("\n‚úÖ ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î‡πÅ‡∏•‡∏∞ Nearest Neighbor Interpolation ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")

# ----------------------------------------------------
# 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Lag-7 Features ‡πÅ‡∏•‡∏∞ Technical Indicators
# ----------------------------------------------------

# 3.1 ‡∏™‡∏£‡πâ‡∏≤‡∏á Lag-7 Features
lag_cols = []
for lag in range(1, 8):
    col_name = f'Close_lag{lag}'
    full_df[col_name] = full_df.groupby('Symbol')['Close'].shift(lag)
    lag_cols.append(col_name)

# 3.2 ‡∏™‡∏£‡πâ‡∏≤‡∏á Technical Indicators
def calculate_technical_indicators(df):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì SMA, RSI, ‡πÅ‡∏•‡∏∞ MACD ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏£‡∏≤‡∏Ñ‡∏≤ Close ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å Interpolate ‡πÅ‡∏•‡πâ‡∏ß"""

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Simple Moving Average (SMA)
    df['SMA_10'] = df.groupby('Symbol')['Close'].transform(lambda x: x.rolling(window=10).mean())
    df['SMA_50'] = df.groupby('Symbol')['Close'].transform(lambda x: x.rolling(window=50).mean())

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Relative Strength Index (RSI - 14 ‡∏ß‡∏±‡∏ô)
    def calculate_rsi(series, window=14):
        # ‡πÉ‡∏ä‡πâ‡∏£‡∏≤‡∏Ñ‡∏≤ Close ‡∏ó‡∏µ‡πà Interpolate ‡πÅ‡∏•‡πâ‡∏ß
        diff = series.diff().dropna()
        gain = (diff.where(diff > 0, 0)).rolling(window=window).mean()
        loss = (-diff.where(diff < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi.fillna(50.0) # RSI ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏≤‡∏á 50.0 ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏≤‡∏°‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î

    df['RSI'] = df.groupby('Symbol')['Close'].transform(calculate_rsi)

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Moving Average Convergence Divergence (MACD)
    df['EMA_12'] = df.groupby('Symbol')['Close'].transform(lambda x: x.ewm(span=12, adjust=False).mean())
    df['EMA_26'] = df.groupby('Symbol')['Close'].transform(lambda x: x.ewm(span=26, adjust=False).mean())
    df['MACD'] = df['EMA_12'] - df['EMA_26']

    return df

full_df = calculate_technical_indicators(full_df)

# 3.3 ‡∏™‡∏£‡πâ‡∏≤‡∏á Target ‡πÅ‡∏•‡∏∞ Flag
full_df['Close_next'] = full_df.groupby('Symbol')['Close'].shift(-1)
full_df['Is_Actual_Target'] = full_df.groupby('Symbol')['Is_Actual_Close'].shift(-1)

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Feature Matrix X ‡πÉ‡∏´‡∏°‡πà
tech_cols = ['SMA_10', 'SMA_50', 'RSI', 'MACD']
X_cols = lag_cols + tech_cols

# ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤ NaN ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Indicators (‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô) ‡∏î‡πâ‡∏ß‡∏¢ 0.0
# ‡πÅ‡∏ñ‡∏ß‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å dropna() ‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô Sliding Window
full_df[tech_cols] = full_df[tech_cols].fillna(0.0)

print(f"\n‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Features ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô: {len(X_cols)} Features")
print(f"Features List: {X_cols}")


# ----------------------------------------------------
# 4. Sliding Window (70/15/15) ‡πÅ‡∏•‡∏∞ Model Training/Evaluation
# ----------------------------------------------------
window_train = 0.7
window_test = 0.15

# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏• (5 ‡πÇ‡∏°‡πÄ‡∏î‡∏•)
models = {
    'Linear': LinearRegression(),
    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),
    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42),
    'XGBoost': XGBRegressor(n_estimators=100, random_state=42, verbosity=0, n_jobs=-1),
    'SVR': SVR()
}

all_results = []
window_predictions_full = []
# ***‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Export ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà***
model_name = "Lag7_TechIndicators_ActualOnly"

# Loop ‡πÅ‡∏ï‡πà‡∏•‡∏∞ Symbol
for sym in tqdm(symbols, desc="Training models with Lag-7 + Tech Indicators"):
    df_sym = full_df[full_df['Symbol'] == sym].sort_values('Date').reset_index(drop=True)

    # Feature, Target ‡πÅ‡∏•‡∏∞ Flag
    data_ml = df_sym[['Date'] + X_cols + ['Close_next', 'Is_Actual_Target']].dropna().reset_index(drop=True)

    X_clean = data_ml[X_cols]
    y_clean = data_ml['Close_next']
    is_actual_target_clean = data_ml['Is_Actual_Target']
    date_clean = data_ml['Date']

    n = len(X_clean)
    step = int(n * window_test)
    start = 0
    window_id = 1

    # Sliding Window Loop
    while start + int(n * window_train) + step <= n:
        train_idx = range(start, start + int(n*window_train))
        test_idx  = range(start + int(n*window_train), start + int(n*window_train) + step)

        X_train = X_clean.iloc[train_idx].values
        y_train = y_clean.iloc[train_idx].values
        X_test  = X_clean.iloc[test_idx].values
        y_test  = y_clean.iloc[test_idx].values

        is_actual_test = is_actual_target_clean.iloc[test_idx].values
        date_test = date_clean.iloc[test_idx].values

        # Scale Training set
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled  = scaler.transform(X_test)

        # Train & Evaluate ‡∏ó‡∏∏‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
        for name, model in models.items():
            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_test_scaled)

            # ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á: ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Target ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏Ñ‡∏≤‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (Is_Actual_Target = 1.0)
            actual_mask = (is_actual_test == 1.0)
            y_test_actual = y_test[actual_mask]
            y_pred_actual = y_pred[actual_mask]

            if len(y_test_actual) > 0:
                 # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Metrics ‡∏ö‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
                 all_results.append({
                    'Symbol': sym,
                    'model': name,
                    'Window': window_id,
                    'start_idx': start,
                    'rmse': np.sqrt(mean_squared_error(y_test_actual, y_pred_actual)),
                    'mae': mean_absolute_error(y_test_actual, y_pred_actual),
                    'r2': r2_score(y_test_actual, y_pred_actual),
                    'Model Name': model_name
                 })

            # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (Predicted vs. Actual)
            temp_df = pd.DataFrame({
                'Date': date_test,
                'Symbol': sym,
                'Window': window_id,
                'model': name,
                'Actual_Close_next': y_test,
                'Predicted_Close_next': y_pred,
                'Is_Actual_Target': is_actual_test
            })
            window_predictions_full.append(temp_df)

        start += step
        window_id += 1

# ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô DataFrame
results_df = pd.DataFrame(all_results)
window_predictions_df = pd.concat(window_predictions_full, axis=0).reset_index(drop=True)

print("\n‚úÖ ‡∏ù‡∏∂‡∏Å‡∏ù‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

# ----------------------------------------------------
# 5. ‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞ Export ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
# ----------------------------------------------------

# Export results_df (‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å Window)
results_df.to_excel("results_TechIndicators_ActualOnly.xlsx", index=False)
print("‚úÖ Exported results (Tech Indicators) to results_TechIndicators_ActualOnly.xlsx")

# ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Average Metrics)
average_results = results_df.groupby('model')[['rmse', 'mae', 'r2']].mean().reset_index()

# ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
format_mapping = {
    'rmse': '{:,.4f}'.format,
    'mae': '{:,.4f}'.format,
    'r2': '{:,.4f}'.format
}
average_results_formatted = average_results.copy()
for col, formatter in format_mapping.items():
    average_results_formatted[col] = average_results_formatted[col].apply(formatter)

print("\n--- üìà ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (Lag-7 + Tech Indicators) ---")
print(average_results_formatted)

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏•‡∏á‡πÉ‡∏ô Excel
average_results.to_excel("average_results_TechIndicators_ActualOnly.xlsx", index=False)
print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏•‡∏á‡πÉ‡∏ô average_results_TechIndicators_ActualOnly.xlsx")

print("\n--- ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå ---")